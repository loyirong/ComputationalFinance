{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"text-align: center; font-size: 300%\"> Computational Finance </p>\n",
    "<img src=\"img/ABSlogo.svg\" alt=\"LOGO\" style=\"display:block; margin-left: auto; margin-right: auto; width: 50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Monte Carlo Methods\n",
    "## Variance Reduction Techniques\n",
    "* In standard Monte Carlo, the length of the confidence interval for $\\theta\\equiv\\mathbb{E}[X]$ is proportional to $\\hat{\\sigma}/\\sqrt{n}$, where $\\sigma$ is the standard deviation of $X$.\n",
    "* Thus to increase the accuracy by a factor of 10 (i.e., gain 1 digit), we need 100 times as many samples.\n",
    "* Variance reduction techniques aim to improve the accuracy of the estimate, without increasing $n$.\n",
    "* We will consider two such techniques: *antithetic sampling*, and *control variates*.\n",
    "* Another powerful technique is *importance sampling*, but this is beyond the scope of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Antithetic Sampling\n",
    "* The crude MC estimate for $\\theta\\equiv \\mathbb{E} [X]$, based on $n$ independent draws $X_i$, is\n",
    "$$\n",
    "\\hat{\\theta}\\equiv \\frac{1}{n}\\sum_{i=1}^n X_i.\n",
    "$$\n",
    "* Now suppose that we can somehow sample $n$ pairs $(X_i, \\tilde X_i)$, such that\n",
    "  * both $X_i$ and $\\tilde X_i$ are drawn from the distribution of $X$;\n",
    "  * the *pairs* $(X_i, \\tilde X_i)$ are independent across $i$;\n",
    "  * for each $i$, $X_i$ and $\\tilde X_i$ are (negatively) correlated.\n",
    "* The antithetic variable estimator is then\n",
    "$$\n",
    "\\hat{\\theta}_{AV}\\equiv \\frac{1}{2}\\left(\\frac{1}{n}\\sum_{i=1}^n X_i+\\frac{1}{n}\\sum_{i=1}^n \\tilde X_i\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Rewriting the estimator as\n",
    "$$\n",
    "\\hat{\\theta}_{AV}=\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{X_i+\\tilde X_i}{2}\\right),\n",
    "$$\n",
    "we see that it is unbiased, and that $\\hat{\\theta}_{AV}$ is the mean of $n$ independent observations $(X_i+\\tilde X_i)/2$, so that the LLN and CLT continue to apply.\n",
    "* Hence, by the CLT,\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}_{AV}-\\theta)\\stackrel d \\rightarrow \\mathrm{N}(0,\\sigma^2_{AV}),\n",
    "$$\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma^2_{AV}&\\equiv \\mathrm{var}\\left[\\frac{X_i+\\tilde X_i}{2}\\right]=\\frac{1}{4}\\left(\\mathrm{var}[X_i]+\\mathrm{var}[\\tilde X_i] +2\\mathrm{cov}[X_i,\\tilde X_i]\\right)\\\\\n",
    "%&=\\frac{1}{2}\\left[\\mathrm{var}[X_i] +\\mathrm{cov}[X_i,\\tilde X_i]\\right)\n",
    "&=\\frac{\\sigma^2}{2}\\big(1+\\rho(X_i,\\tilde X_i)\\big).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Comparing the variance of $\\hat{\\theta}_{AV}$, $\\frac{1}{n}\\sigma^2_{AV}$, with that of the crude estimator based on $2n$ observations $\\left(\\frac{1}{2n}\\sigma^2\\right)$, we see that efficiency is gained whenever the correlation $\\rho(X_i,\\tilde X_i)$ is negative.\n",
    "* So how do we draw correlated random numbers $X_i$ and $\\tilde X_i$?\n",
    "* One way is as follows: our simulations are typically based on an array of standard normal random numbers $\\mathbf{z}_i$, i.e., $X_i=f(\\mathbf{z}_i)$. Setting $\\tilde X_i=f(-\\mathbf{z}_i)$ will often do the trick. \n",
    "* Note for standard Brownian motion, this corresponds to flipping the path about the abscissa.\n",
    "* Let's modify last week's `bmsim_vec` and `asianmc_vec` to use antithetic sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def bmsim_vec(T, N, X0=0, mu=0, sigma=1, numsim=1, av=False):\n",
    "    \"\"\"Simulate `numsim` Brownian motion paths. If av=True, then 2*`numsim` paths are returned,\n",
    "    where paths numsim:2numsim+1 are the antithetic paths.\n",
    "    \"\"\"\n",
    "    deltaT = float(T)/N\n",
    "    tvec = np.linspace(0, T, N+1)\n",
    "    z = np.random.randn(numsim, N+1)\n",
    "    if av:\n",
    "        z = np.concatenate((z, -z))\n",
    "    dX = mu*deltaT + sigma*np.sqrt(deltaT)*z\n",
    "    dX[:, 0] = 0.\n",
    "    X = np.cumsum(dX, axis=1)\n",
    "    X += X0    \n",
    "    return tvec, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def asianmc_vec(S0, K, T, r, sigma, delta, N, numsim=10000, av=False):\n",
    "    \"\"\"Monte Carlo price of an arithmetic average Asian call.\n",
    "    Pass `av=True` to use antithetic sampling.\n",
    "    \"\"\"\n",
    "    X0 = np.log(S0)\n",
    "    nu = r-delta-.5*sigma**2    \n",
    "    _, X = bmsim_vec(T, N, X0, nu, sigma, numsim, av)\n",
    "    S = np.exp(X)\n",
    "    payoffs = np.maximum(S[:, 1:].mean(axis=1)-K, 0.)\n",
    "    g = np.exp(-r*T)*payoffs\n",
    "    if av:\n",
    "        g = .5*(g[:numsim]+g[numsim:])    \n",
    "    C = g.mean(); s = g.std()\n",
    "    zq = norm.ppf(0.975)\n",
    "    Cl = C - zq/np.sqrt(numsim)*s\n",
    "    Cu = C + zq/np.sqrt(numsim)*s\n",
    "    return C, Cl, Cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0927262054551385, 0.03592162508407748)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S0 = 11; K = 10; T = 3/12.; r = 0.02; sigma = .3; delta = 0.01; N = 10; numsim=10000\n",
    "np.random.seed(0)\n",
    "C, Cl, Cu = asianmc_vec(S0, K, T, r, sigma, delta, N, numsim, av=False)\n",
    "C, Cu-Cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0824190804865295, 0.012604081385357624)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "C, Cl, Cu = asianmc_vec(S0, K, T, r, sigma, delta, N, numsim/2, True)\n",
    "C, Cu-Cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not bad. The new interval is about 1/3 as long, with the same amount of work.\n",
    "* Timings aren't much different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.86 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit asianmc_vec(S0, K, T, r, sigma, delta, N, numsim, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit asianmc_vec(S0, K, T, r, sigma, delta, N, numsim/2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Control Variates\n",
    "* Antithetic sampling is a general technique that requires little knowledge about the system being simulated.\n",
    "* Another variance reduction technique is based on *control variates*. It requires a deeper understanding of the problem, but can yield excellent results.\n",
    "* Suppose again that we want to estimate $\\theta\\equiv\\mathbb{E}[X]$.\n",
    "* Further suppose that there is another random variable, $Y$, correlated with $X$, with known mean $\\mu\\equiv\\mathbb{E}[Y]$.\n",
    "* Example: $X$ is the discounted payoff of an option and $\\theta$ its unknown price. $Y$ is the discounted payoff of a second option which unlike the first, can be priced analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Suppose we can draw $n$ pairs $(X_i, Y_i)$, i.i.d. across $i$.  The control variate estimator, for a given constant $c$ , is\n",
    "$$\n",
    "\\hat{\\theta}_c\\equiv \\bar{X}_n-c(\\bar{Y}_n-\\mu).\n",
    "$$\n",
    "* Intuition: suppose $X$ and $Y$ are positively correlated and $c>0$. If, due to sampling variation, $\\bar{Y}_n>\\mu$ for a given set of replications, then it is likely that also $\\bar{X}_n>\\theta$, so it should be corrected downwards.\n",
    "* The estimator is unbiased:\n",
    "$$\n",
    "\\mathbb{E}[\\hat{\\theta}_c]=\\mathbb{E}[\\bar{X}_n]-c\\mathbb{E}[\\bar{Y}_n-\\mu]=\\theta.\\tag{$\\dagger$}\n",
    "$$\n",
    "* Let $Z_i\\equiv X_i-c(Y_i-\\mu)$. Then\n",
    "$\n",
    "\\hat{\\theta}_c=n^{-1}\\sum_{i=1}^n Z_i,\n",
    "$\n",
    "a sum of $n$ i.i.d. terms, so the LLN and CLT apply. Thus\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}_c-\\theta)\\stackrel d \\rightarrow \\mathrm{N}(0,\\sigma^2_{CV}),\n",
    "$$\n",
    "where $\\sigma^2_{CV}\\equiv\\mathrm{var}(Z_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The variance is seen to be\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma^2_{CV}&\\equiv\\mathrm{var}(Z_i)=\\mathrm{var}\\big(X_i-c(Y_i-\\mu)\\big)\\\\&=\\sigma^2-2c\\;\\mathrm{cov}(X,Y)+c^2\\mathrm{var}(Y).\n",
    "\\end{align*}\n",
    "* It remains to choose $c$. The optimal $c$ minimizes $\\sigma^2_{CV}$, yielding the FOC\n",
    "\n",
    "$$\n",
    "0=-2\\mathrm{cov}(X,Y)+2c^\\ast\\mathrm{var}(Y)\\quad\\Leftrightarrow\\quad c^\\ast=\\frac{\\mathrm{cov}(X,Y)}{\\mathrm{var}(Y)}.\n",
    "$$\n",
    "* With this choice,\n",
    "\n",
    "$$\n",
    "\\sigma^2_{CV}=\\sigma^2-2\\frac{\\mathrm{cov}^2(X,Y)}{\\mathrm{var}(Y)}+\\frac{\\mathrm{cov}^2(X,Y)}{\\mathrm{var}(Y)},\n",
    "$$\n",
    "or\n",
    "$$\n",
    "\\frac{\\sigma^2_{CV}}{\\sigma^2}=1-\\rho^2(X,Y).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* We see that the variance is reduced whenever $\\rho(X,Y)\\neq 0$.\n",
    "* In practice $c^\\ast=\\mathrm{cov}(X,Y)/\\mathrm{var}(Y)$ is unknown. A consistent estimator is $\\hat{c}\\equiv S_{X,Y}/S^2_{Y}$, which can be obtained by regressing $X$ on $Y$ and a constant.\n",
    "* $\\hat{c}$ is random and not independent of $Y$. In view of $(\\dagger)$, this introduces a bias in $\\hat{\\theta}_{\\hat{c}}$, because we cannot take it out of the expectation. Usually this bias is\n",
    "small (and disappears asymptotically).\n",
    "*  The standard errors (and thus the CI) would also need to be adjusted. We just ignore these difficulties.\n",
    "* The usefulness of the method hinges on the availability of good control variates. A good control variate has $|\\rho(X,Y)|$ close to 1, i.e., a strong linear relationship with $X$. It is possible to incorporate several control variates.\n",
    "* Control variates and antithetic sampling can be combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Classic example: using the geometric average asian call (which can be priced analytically) as a control variate for an arithmetic average call (which cannot).\n",
    "* The geometric average call has payoff\n",
    "$$\n",
    "C^{\\mathrm{Geo}}_T=\\Big(\\prod_{i=1}^N S_{t_i}^{1/N}-K\\Big)^+=\\exp\\Big(\\frac{1}{N}\\sum_{i=1}^N X_{t_i}-K \\Big)^+, \\qquad X_t\\equiv \\log S_t.\n",
    "$$\n",
    "* Assuming that $t_i=i\\delta t$, it can be shown that \n",
    "$$\n",
    "C^{\\mathrm{Geo}}_0=e^{(\\hat{\\mu}-r)T}S_0\\Phi(\\hat{d}_1)-e^{-rT}K\\Phi(\\hat{d}_2),\n",
    "$$\n",
    "where\n",
    "\n",
    "\\begin{alignat*}{2}\n",
    "\\hat{d}_1&\\equiv\\frac{\\log (S_0/K)+(\\hat{\\mu}+\\frac{1}{2}\\hat{\\sigma}^2)T}{\\hat{\\sigma} \\sqrt{T}}, \\qquad &\\hat{d}_2&\\equiv\\hat{d}_1-\\hat{\\sigma}\\sqrt{T},\\\\\n",
    "\\hat{\\sigma}&\\equiv\\sigma\\sqrt{\\frac{(N+1)(2N+1)}{6N^2}},\\quad\\mbox{and }& \\hat{\\mu}&\\equiv\\frac{\\hat{\\sigma}^2}{2}+\\left(r-\\delta-\\frac{\\sigma^2}{2}\\right)\\frac{N+1}{2N},\n",
    "\\end{alignat*}\n",
    "valid only at the time the option is written; the general formula is more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def asiancall_geo(S0, K, T, r, sigma, delta, N):\n",
    "    \"\"\"Price of a geometric average price asian call.\"\"\"\n",
    "    shat = sigma * np.sqrt(((N+1) * (2*N+1)) / (6.0 * N**2))\n",
    "    mhat = shat**2/2.0 + (r-delta-.5*sigma**2) * (N+1)/(2.0*N)\n",
    "    d1 = (np.log(S0/float(K)) + T*(mhat + 0.5*shat**2)) / shat / np.sqrt(T)\n",
    "    d2 = d1-shat*np.sqrt(T)\n",
    "    Price = np.exp((mhat-r)*T)*S0*norm.cdf(d1)-np.exp(-r*T)*K*norm.cdf(d2)\n",
    "    return Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def asianmc_cv(S0, K, T, r, sigma, delta, N, numsim=10000):\n",
    "    \"\"\"Monte Carlo price of an arithmetic average Asian call using control variates.\n",
    "    Pass `av=True` to use antithetic sampling.\n",
    "    \"\"\"\n",
    "    X0 = np.log(S0)\n",
    "    nu = r-delta-.5*sigma**2    \n",
    "    _, X = bmsim_vec(T, N, X0, nu, sigma, numsim)\n",
    "    S = np.exp(X)\n",
    "    mu = asiancall_geo(S0, K, T, r, sigma, delta, N)\n",
    "    payoffs = np.maximum(S[:, 1:].mean(axis=1)-K, 0.)\n",
    "    control = np.maximum(np.exp(X[:, 1:].mean(axis=1))-K, 0.)\n",
    "    c = (np.cov(payoffs, control)/np.var(control))[0, 1]\n",
    "    g = np.exp(-r*T)*payoffs - c*(np.exp(-r*T)*control-mu)\n",
    "    C = g.mean(); s = g.std()\n",
    "    zq = norm.ppf(0.975)\n",
    "    Cl = C - zq/np.sqrt(numsim)*s\n",
    "    Cu = C + zq/np.sqrt(numsim)*s\n",
    "    return C, Cl, Cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0835205424516814, 0.00060646107619888312)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "C, Cl, Cu = asianmc_cv(S0, K, T, r, sigma, delta, 10, numsim)\n",
    "C, Cu-Cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wow. Obviously the two payoffs are very highly correlated. \n",
    "* Timings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.87 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit asianmc_vec(S0, K, T, r, sigma, delta, N, numsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.51 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit asianmc_cv(S0, K, T, r, sigma, delta, N, numsim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Expat Conundrum: Greeks in Monte Carlo\n",
    "* So far we were mostly concerned with *pricing* options. An equally important problem in practice is *hedging*.\n",
    "Suppose that a financial institution has issued a call option (i.e., it is short the option). In order to eliminate the risk, it might create the hedge\n",
    "$$\n",
    "\\Pi _{t}\\equiv-C_{t}+\\phi _{t}S_{t},\n",
    "$$\n",
    "where $\\phi_{t}$ is a number of stocks. The *delta-hedged* portfolio has\n",
    "$$\n",
    "\\phi _{t}=\\Delta_t\\equiv \\frac{\\partial C_{t}}{\\partial S_{t}}.\n",
    "$$\n",
    "* This position is *delta-neutral*: it is immune to (infinitesimally) small movements of the underlying.\n",
    "* The portfolio has to be rebalanced every time the underlying moves (because $\\Delta_t$ depends on time), incurring trading costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If there is another instrument on the same underlying available, then it is possible to construct a portfolio that is also *gamma-neutral*. Gamma is defined as\n",
    "$$\n",
    "\\Gamma_t\\equiv \\frac{\\partial^2 C_{t}}{\\partial S^2_{t}}.\n",
    "$$\n",
    "Such a portfolio may need to be readjusted less frequently.\n",
    "* $\\Delta_t$ and $\\Gamma_t$ are examples of the so-called option *Greeks*. Other examples are $\\theta_t$ (the derivative with respect to time), $\\rho_t$ (w.r.t. $r$), and $\\mathcal{V}_t$ (\"Vega\", w.r.t. $\\sigma$).\n",
    "* In the BS model, the latter two parameters are constant, but in practice they are not.\n",
    "* In order to construct a hedge, it is important that we be able to compute the Greeks. This is easy if we have an analytical expression for the price; e.g., for a European call in the BS model, it can be shown\n",
    "that\n",
    "$$\n",
    "\\Delta_t=e^{-\\delta(T-t)}\\Phi(d_1).\n",
    "$$\n",
    "* Chapter 18 of Hull (2012) lists the expressions for the other Greeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If the option cannot be priced analytically, then we may need to resort to Monte Carlo.\n",
    "* Recalling our risk neutral pricing formula,\n",
    "$$\n",
    "\\Delta_0=\\frac{\\partial}{\\partial S_0} \\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}C_T(S_0)\\right].\n",
    "$$\n",
    "* In view of the definition of the derivative,\n",
    "$$\n",
    "\\Delta_0= \\lim_{\\delta S_0\\rightarrow 0} \\frac{\\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}C_T(S_0+\\delta S_0)\\right]-\\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}C_T(S_0)\\right]}{\\delta S_0},\n",
    "$$\n",
    "it is natural to approximate $\\Delta_0$ with a finite difference quotient for some small $\\delta S_0$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5653871014334575"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dS = .01 \n",
    "np.random.seed(0)\n",
    "Cd, _, _ = asianmc_vec(S0+dS, K, T, r, sigma, delta, N, numsim)\n",
    "C,  _, _ = asianmc_vec(S0,    K, T, r, sigma, delta, N, numsim)\n",
    "Delta = (Cd-C)/dS; Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The true answer is around 0.858."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " * Let's try to improve the approximation by reducing $\\delta S_0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.886858496600313"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dS = .001; np.random.seed(0)\n",
    "Cd, _, _ = asianmc_vec(S0+dS, K, T, r, sigma, delta, N, numsim)\n",
    "C,  _, _ = asianmc_vec(S0,    K, T, r, sigma, delta, N, numsim)\n",
    "Delta = (Cd-C)/dS; Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ouch. What's happeing is that as $\\delta S_0\\rightarrow 0$, the sampling variation in $C_T$ increasingly dominates the variation from a small perturbation of $S_0$. This increases the variance of the estimator (which is nevertheless unbiased as $\\delta S_0\\rightarrow 0$).\n",
    "* The trick is to use the same random numbers in both simulation runs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86224510458587922"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dS = .001; np.random.seed(0)\n",
    "Cd, _, _ = asianmc_vec(S0+dS, K, T, r, sigma, delta, N, numsim)\n",
    "np.random.seed(0)\n",
    "C,  _, _ = asianmc_vec(S0,    K, T, r, sigma, delta, N, numsim)\n",
    "Delta = (Cd-C)/dS; Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Essentially, the method of common random numbers amounts to the approximation\n",
    "$$\n",
    "\\Delta_0\\approx \\mathbb{E}^{\\mathbb{Q}}\\left[\\frac{e^{-rT}C_T(S_0+\\delta S_0)-e^{-rT}C_T(S_0)}{\\delta S_0}\\right].\n",
    "$$\n",
    "* The validity of this approach hinges on whether it is justified to take the limit in the above expression, i.e., whether we may exchange the order of derivative and expectation so that\n",
    "$$\n",
    "\\frac{\\partial}{\\partial S_0} \\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}C_T(S_0)\\right]= \\mathbb{E}^{\\mathbb{Q}}\\left[\\frac{\\partial}{\\partial S_0} e^{-rT}C_T(S_0)\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The approach can be made more explicit. The random variable of interest is\n",
    "$$\n",
    "e^{-rT}C_T=e^{-rT}(S_T-K)^+,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "S_T=S_0e^{(r-\\delta-\\sigma^2/2)T+\\sigma\\sqrt{T}Z},\\quad Z\\sim N(0,1).\n",
    "$$\n",
    "* By the chain rule,\n",
    "$$\n",
    "\\frac{\\partial C_T }{\\partial S_0 }=\\frac{\\partial C_T}{\\partial S_T}\\frac{\\partial S_T}{\\partial S_0}.\n",
    "$$\n",
    "* We have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial S_T}{\\partial S_0}= \\frac{S_T}{S_0}\\quad\\mbox{and}\\quad \\frac{\\partial C_T}{\\partial S_T} =\\begin{cases}0, &\\mbox{if } S_T\\lt K\\\\1, &\\mbox{if } S_T\\gt K\\end{cases}.\n",
    "$$\n",
    "* The latter is undefined at $S_T=K$, but this happens with zero probability. Hence\n",
    "$$\n",
    "\\frac{\\partial C_T}{\\partial S_0}=\\frac{S_T}{S_0} \\mathbf{1}_{S_T\\gt K}.\\tag{$\\ddagger$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Thus, provided the exchange of derivative and expectation is valid, we have\n",
    "$$\n",
    "\\Delta_0=\\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}\\frac{S_T}{S_0} \\mathbf{1}_{S_T>K}\\right].\n",
    "$$\n",
    "* This is called the *pathwise estimate*, because we are keeping the asset path (the random numbers) the same when taking difference / derivatives.\n",
    "* A similar derivation shows that for the arithmetic average asian call,\n",
    "$$\n",
    "\\Delta_0=\\mathbb{E}^{\\mathbb{Q}}\\left[e^{-rT}\\frac{\\bar{S}_T}{S_0} \\mathbf{1}_{\\bar S_T>K} \\right].\n",
    "$$\n",
    "This is genuinely useful, as no closed form expression exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Notes:\n",
    "  * Unlike the simple common-random-numbers approach, the explicit pathwise approach allows us to construct a CI.\n",
    "  * Antithetic sampling and control variates can be used just like for prices.\n",
    "  * The validity of the method depends on whether the exchange of derivative and expectation is valid; a necessary condition for this is continuity of the payoff function. Thus, the method fails for, e.g., binary options (note that there, $\\partial C_T/\\partial S_T=0$ almost everywhere).\n",
    "  * This also implies that the method cannot be applied to second derivatives such as the option gamma; observe that ($\\ddagger$) is discontinuous.  Alternatives include the *likelihood ratio method*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* We apply the method to the Asian option.\n",
    "* In order to use a control variate, we first modify `asiancall_geo` to also return the delta of the option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def asiancall_geo2(S0, K, T, r, sigma, delta, N):\n",
    "    \"\"\"Price of a geometric average price asian call.\"\"\"\n",
    "    shat = sigma * np.sqrt(((N+1) * (2*N+1)) / (6.0 * N**2))\n",
    "    mhat = shat**2/2.0 + (r-delta-.5*sigma**2) * (N+1)/(2.0*N)\n",
    "    d1 = (np.log(S0/float(K)) + T*(mhat + 0.5*shat**2)) / shat / np.sqrt(T)\n",
    "    d2 = d1-shat*np.sqrt(T)\n",
    "    Price = np.exp((mhat-r)*T)*S0*norm.cdf(d1)-np.exp(-r*T)*K*norm.cdf(d2)\n",
    "    Delta = np.exp((mhat-r)*T)*norm.cdf(d1)\n",
    "    return Price, Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We'll call the final version of our code, which combines vectorization, antithetic sampling, and control variates for both the price and the Delta `asianMC`.\n",
    "* To make it easier to use, the function returns a [named tuple](https://docs.python.org/2/library/collections.html#collections.namedtuple) containing the simulation results, instead of a bunch of scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "MonteCarloResults=namedtuple(\"MonteCarloResults\", [\"Price\", \"Cl\", \"Cu\", \"Delta\", \"Dl\", \"Du\"])\n",
    "def asianMC(S0, K, T, r, sigma, delta, N, numsim=10000, av=True):\n",
    "    \"\"\"Price and Delta of an arithmetic average Asian call using control variates.\n",
    "    Pass `av=True` to use antithetic sampling.\n",
    "    \"\"\"\n",
    "    X0 = np.log(S0); nu = r-delta-.5*sigma**2    \n",
    "    _, X = bmsim_vec(T, N, X0, nu, sigma, numsim, av)\n",
    "    S = np.exp(X)\n",
    "    mu, D = asiancall_geo2(S0, K, T, r, sigma, delta, N)\n",
    "    payoffs = np.maximum(S[:, 1:].mean(axis=1)-K, 0.)\n",
    "    control1 = np.maximum(np.exp(X[:, 1:].mean(axis=1))-K, 0.)\n",
    "    deltas = (payoffs > 0)/float(S0)*S[:, 1:].mean(axis=1)\n",
    "    control2 = (control1 > 0)/float(S0)*np.exp(X[:, 1:].mean(axis=1))\n",
    "    c1 = (np.cov(payoffs, control1)/np.var(control1))[0, 1]\n",
    "    c2 = (np.cov(deltas, control2)/np.var(control2))[0, 1]\n",
    "    g1 = np.exp(-r*T)*payoffs - c1*(np.exp(-r*T)*control1-mu)\n",
    "    g2 = np.exp(-r*T)*deltas - c2*(np.exp(-r*T)*control2-D)\n",
    "    if av:\n",
    "        g1 = .5*(g1[:numsim]+g1[numsim:])    \n",
    "        g2 = .5*(g2[:numsim]+g2[numsim:])    \n",
    "    C = g1.mean(); s1 = g1.std(); zq = norm.ppf(0.975)\n",
    "    Cl = C - zq/np.sqrt(numsim)*s1\n",
    "    Cu = C + zq/np.sqrt(numsim)*s1\n",
    "    Delta = g2.mean(); s2 = g2.std()\n",
    "    Dl = Delta - zq/np.sqrt(numsim)*s2\n",
    "    Du = Delta + zq/np.sqrt(numsim)*s2\n",
    "    return MonteCarloResults(C, Cl, Cu, Delta, Dl, Du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.083446296903571, 0.85870108333211115)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "results=asianMC(S0, K, T, r, sigma, delta, N)\n",
    "results.Price, results.Delta"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "livereveal": {
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
